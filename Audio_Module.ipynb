{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio_Module.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNP8sN9Rh0W3hI/PYASVlb+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SayuriRavihari/ACM-ICPC-Algorithms/blob/master/Audio_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_yYV6YRZvAB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a3cf63-4ede-4d00-84f2-d0dc8fd78d32"
      },
      "source": [
        "import os\n",
        "import librosa\n",
        "import joblib\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlMLCkqIcNO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c297a0a-529a-4d55-cd39-23bfe6d80efe"
      },
      "source": [
        "#create spectrograms\n",
        "import numpy as np\n",
        "from numpy.lib import stride_tricks\n",
        "import os\n",
        "import scipy.io.wavfile as wav\n",
        "\"\"\"\n",
        "This script creates spectrogram matrices from wav files that can be passed \\\n",
        "to the CNN. This was heavily adopted from Frank Zalkow's work.\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Short-time Fourier transform of audio signal.  \n",
        "\"\"\"\n",
        "def stft(sig, frameSize, overlapFac=0.5, window=np.hanning):\n",
        "   \n",
        "    win = window(frameSize)\n",
        "    hopSize = int(frameSize - np.floor(overlapFac * frameSize))\n",
        "    # zeros at beginning (thus center of 1st window should be for sample nr. 0)\n",
        "    samples = np.append(np.zeros(int(np.floor(frameSize/2.0))), sig)\n",
        "    # cols for windowing\n",
        "    cols = np.ceil((len(samples) - frameSize) / float(hopSize)) + 1\n",
        "    # zeros at end (thus samples can be fully covered by frames)\n",
        "    samples = np.append(samples, np.zeros(frameSize))\n",
        "    frames = stride_tricks.as_strided(samples, shape=(int(cols), int(frameSize)),\n",
        "                                      strides=(samples.strides[0]*hopSize,\n",
        "                                      samples.strides[0])).copy()\n",
        "    frames *= win\n",
        "    return np.fft.rfft(frames)\n",
        "\n",
        "\"\"\"\n",
        "Scale frequency axis logarithmically.\n",
        "\"\"\"\n",
        "def logscale_spec(spec, sr=44100, factor=20.):\n",
        "   \n",
        "    timebins, freqbins = np.shape(spec)\n",
        "\n",
        "    scale = np.linspace(0, 1, freqbins) ** factor\n",
        "    scale *= (freqbins-1)/max(scale)\n",
        "    scale = np.unique(np.round(scale))\n",
        "\n",
        "    # create spectrogram with new freq bins\n",
        "    newspec = np.complex128(np.zeros([timebins, len(scale)]))\n",
        "    for i in range(0, len(scale)):\n",
        "        if i == len(scale)-1:\n",
        "            newspec[:, i] = np.sum(spec[:, int(scale[i]):], axis=1)\n",
        "        else:\n",
        "            newspec[:, i] = np.sum(spec[:, int(scale[i]):int(scale[i+1])], axis=1)\n",
        "\n",
        "    # list center freq of bins\n",
        "    allfreqs = np.abs(np.fft.fftfreq(freqbins*2, 1./sr)[:freqbins+1])\n",
        "    freqs = []\n",
        "    for i in range(0, len(scale)):\n",
        "        if i == len(scale)-1:\n",
        "            freqs += [np.mean(allfreqs[int(scale[i]):])]\n",
        "        else:\n",
        "            freqs += [np.mean(allfreqs[int(scale[i]):int(scale[i+1])])]\n",
        "\n",
        "    return newspec, freqs\n",
        "print('done')\n",
        "  \n",
        "def stft_matrix(audiopath, binsize=2**10, offset=0):\n",
        "    \"\"\"\n",
        "    A function that converts a wav file into a spectrogram represented by a \\\n",
        "    matrix where rows represent frequency bins, columns represent time, and \\\n",
        "    the values of the matrix represent the decibel intensity. A matrix of \\\n",
        "    this form can be passed as input to the CNN after undergoing normalization.\n",
        "    \"\"\"\n",
        "    samplerate, samples = wav.read(audiopath)\n",
        "    s = stft(samples, binsize)\n",
        "\n",
        "    sshow, freq = logscale_spec(s, factor=1, sr=samplerate)\n",
        "    ims = 20.*np.log10(np.abs(sshow)/10e-6)  # amplitude to decibel\n",
        "    timebins, freqbins = np.shape(ims)\n",
        "\n",
        "    ims = np.transpose(ims)\n",
        "    ims = np.flipud(ims)  # weird - not sure why it needs flipping\n",
        "\n",
        "    return ims"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFUb3ZnkcwUT"
      },
      "source": [
        "base = '/content/drive/My Drive/Audio_Data/Dataset/'\n",
        "durr_array = []\n",
        "dataset = {}\n",
        "for i in os.listdir(base):\n",
        "  print(i)\n",
        "  d = []\n",
        "  for j in os.listdir(base+i):\n",
        "    x = stft_matrix(base+i+'/'+j)\n",
        "    sh = x.shape[1]\n",
        "    if (sh>=100):\n",
        "      n = int(sh/100)\n",
        "      for ii in range(n):\n",
        "        d.append(x[:,ii*100:(ii+1)*100])\n",
        "      \n",
        "    else:\n",
        "      n = int(100/sh)\n",
        "      y = x\n",
        "      for jj in range(n):\n",
        "        y = np.concatenate((y,x),axis=1)\n",
        "      d.append(y[:,:100])\n",
        "    \n",
        "  dataset[i] = d\n",
        "\n",
        "joblib.dump(dataset, '/content/drive/My Drive/Audio_Data/dataset.joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0bk7jmlbSUX"
      },
      "source": [
        "dataset = joblib.load('/content/drive/My Drive/Audio_Data/Dataset/dataset.joblib')\n",
        "\n",
        "new_dataset = {}\n",
        "\n",
        "for key in dataset:\n",
        "  temp = []\n",
        "  for i in dataset[key]:\n",
        "    if np.all(np.isfinite(i)):\n",
        "      temp.append(i)\n",
        "  new_dataset[key] = temp\n",
        "\n",
        "dataset = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNWrk4TX4VJK"
      },
      "source": [
        "def preprocess(X_train, X_test):\n",
        "    \"\"\"\n",
        "    Convert from float64 to float32 and normalize normalize to decibels\n",
        "    relative to full scale (dBFS) for the 4 sec clip.\n",
        "    \"\"\"\n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "\n",
        "    X_train = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_train])\n",
        "    X_test = np.array([(X - X.min()) / (X.max() - X.min()) for X in X_test])\n",
        "    return X_train, X_test\n",
        "\n",
        "\n",
        "def prep_train_test(X_train, y_train, X_test, y_test, nb_classes):\n",
        "    \"\"\"\n",
        "    Prep samples ands labels for Keras input by noramalzing and converting\n",
        "    labels to a categorical representation.\n",
        "    \"\"\"\n",
        "    print('Train on {} samples, validate on {}'.format(X_train.shape[0],\n",
        "                                                       X_test.shape[0]))\n",
        "\n",
        "    # normalize to dBfS\n",
        "    X_train, X_test = preprocess(X_train, X_test)\n",
        "\n",
        "    # Convert class vectors to binary class matrices\n",
        "    Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "    Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "    return X_train, X_test, Y_train, Y_test\n",
        "    print('done')\n",
        "\n",
        "\"\"\"\n",
        "def cnn(X_train, y_train, X_test, y_test, batch_size,\n",
        "        nb_classes, epochs, input_shape):\n",
        "    \n",
        "    The Convolutional Neural Net architecture for classifying the audio clips\n",
        "    as normal (0) or depressed (1).\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (5, 5), input_shape=input_shape, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(nb_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
        "                        verbose=1, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate accuracy on test and train sets\n",
        "    score_train = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print('Train accuracy:', score_train[1])\n",
        "    score_test = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print('Test accuracy:', score_test[1])\n",
        "\n",
        "    return model, history\n",
        "    \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzQkbg5N4WHS"
      },
      "source": [
        "nb_classes = 11\n",
        "labels_map = {'Scary Sounds':0,'Fights':1,'Animal Sounds':2, 'Cheering':3, 'Vehicle Sounds':4, 'Shouting':5, 'Gunshots':6, 'Music':7, 'Explosions':8, 'Fire':9, 'Nature':10}\n",
        "\n",
        "train_data = []\n",
        "train_labels = []\n",
        "test_data = []\n",
        "test_labels = []\n",
        "\n",
        "for key in new_dataset:\n",
        "  value = new_dataset[key]\n",
        "  random.shuffle(value)\n",
        "  length = int(len(value)*0.8)\n",
        "  train_data.extend(value[:length])\n",
        "  train_labels.extend([labels_map[key] for x in range(length)])\n",
        "\n",
        "  test_data.extend(value[length:])\n",
        "  test_labels.extend([labels_map[key] for x in range(len(value) - length)])\n",
        "\n",
        "\n",
        "train_data, test_data, train_labels, test_labels = prep_train_test(np.array(train_data), np.array(train_labels), np.array(test_data), np.array(test_labels), nb_classes)\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_data, train_labels, test_size=0.2, stratify=train_labels, random_state=42)\n",
        "\n",
        "new_dataset = {}\n",
        "train_data = []\n",
        "train_labels = []"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}